ftg{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d99268-1579-4183-b249-18d3a2893264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b2c9f-c0be-4024-a1c7-1167cc732806",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b89c2a-9c79-4cf2-934e-250387976ba3",
   "metadata": {},
   "source": [
    "- Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb2ae89-ea83-4b96-a4a9-63ef85102c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd7be7-e371-4596-a5fd-b164a41b1524",
   "metadata": {},
   "source": [
    "- Show head of data (first 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d024bd-bcd8-4d0c-9189-265601916b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d305e9-c8e0-4f7b-b2b4-0d823c48c45d",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b32dffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTINUOUS_FEATURES = ['LotArea', 'YearBuilt']\n",
    "CATEGORICAL_FEATURES = ['Neighborhood', 'BldgType']\n",
    "TARGET = 'SalePrice'\n",
    "MODEL_PATH = 'C:/Users/Ananya/dsp-ananya-gownivari-ravindrareddy/models/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159070e2",
   "metadata": {},
   "source": [
    "## Compute RMLSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bccdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmsle(y_true: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    \"\"\"Function to compute Root Mean Squared Logarithmic Error (RMSLE).\"\"\"\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return round(rmsle, precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4c2d1-88e4-4937-8506-eb40d7728a7a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7460da-d0fc-4d28-ac1c-594c4b4286c1",
   "metadata": {},
   "source": [
    "- Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c21fbc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame, continuous_features: list, categorical_features: list, target: str) -> dict:\n",
    "    \"\"\"Function to build, train, and save the model and preprocessors.\"\"\"\n",
    "    # Split dataset into features and target\n",
    "    X = data[continuous_features + categorical_features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a856eeb",
   "metadata": {},
   "source": [
    "## Model Building and Traning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80aa515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(data: pd.DataFrame, continuous_features: list, categorical_features: list, target: str) -> dict:\n",
    "    \"\"\"Function to build, train, and save the model and preprocessors.\"\"\"\n",
    "    # Split dataset into features and target\n",
    "    X = data[continuous_features + categorical_features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define pre-processing for categorical features\n",
    "    onehot = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    onehot.fit(X_train[categorical_features])\n",
    "    \n",
    "    # Define pre-processing for continuous features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[continuous_features])\n",
    "\n",
    "    # Transform the training data\n",
    "    X_train_categorical = onehot.transform(X_train[categorical_features])\n",
    "    X_train_continuous = scaler.transform(X_train[continuous_features])\n",
    "\n",
    "    # Combine processed features\n",
    "    X_train_processed = np.hstack([X_train_categorical, X_train_continuous])\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    # Save the model and preprocessors\n",
    "    os.makedirs(MODEL_PATH, exist_ok=True)  # Create directory if it doesn't exist\n",
    "    joblib.dump(scaler, os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "    joblib.dump(onehot, os.path.join(MODEL_PATH, 'Encoder.joblib'))\n",
    "    joblib.dump(model, os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test_categorical = onehot.transform(X_test[categorical_features])\n",
    "    X_test_continuous = scaler.transform(X_test[continuous_features])\n",
    "    X_test_processed = np.hstack([X_test_categorical, X_test_continuous])\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    rmsle = compute_rmsle(y_test, y_pred)\n",
    "    return {'rmsle': rmsle}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984381e0-de24-42b2-880b-6326d9ea45d3",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad83a0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(input_data: pd.DataFrame, continuous_features: list, categorical_features: list) -> np.ndarray:\n",
    "    \"\"\"Function to make predictions using the saved model and preprocessors.\"\"\"\n",
    "    # Load the model and preprocessors\n",
    "    loaded_model = joblib.load(os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "    loaded_onehot = joblib.load(os.path.join(MODEL_PATH, 'Encoder.joblib'))\n",
    "    loaded_scaler = joblib.load(os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "\n",
    "    # Preprocess the input data\n",
    "    X_new_categorical = loaded_onehot.transform(input_data[categorical_features])\n",
    "    X_new_continuous = loaded_scaler.transform(input_data[continuous_features])\n",
    "    X_new_processed = np.hstack([X_new_categorical, X_new_continuous])\n",
    "\n",
    "    # Make predictions\n",
    "    new_predictions = loaded_model.predict(X_new_processed)\n",
    "    return new_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6102ec7",
   "metadata": {},
   "source": [
    "## Load New data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14c8816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: {'rmsle': 0.27}\n",
      "      PredictedSalePrice\n",
      "0               152384.0\n",
      "1               152896.0\n",
      "2               197824.0\n",
      "3               193792.0\n",
      "4               262080.0\n",
      "...                  ...\n",
      "1454             83072.0\n",
      "1455            102656.0\n",
      "1456            155456.0\n",
      "1457            174272.0\n",
      "1458            174208.0\n",
      "\n",
      "[1459 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load the training data\n",
    "    train_data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/train.csv')\n",
    "\n",
    "    # Build the model and get performance metrics\n",
    "    performance = build_model(train_data, CONTINUOUS_FEATURES, CATEGORICAL_FEATURES, TARGET)\n",
    "    print(f'Model Performance: {performance}')\n",
    "\n",
    "    # Load the new data\n",
    "    new_data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/test.csv')\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = make_predictions(new_data, CONTINUOUS_FEATURES, CATEGORICAL_FEATURES)\n",
    "    new_data['PredictedSalePrice'] = predictions\n",
    "    print(new_data[['PredictedSalePrice']])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
