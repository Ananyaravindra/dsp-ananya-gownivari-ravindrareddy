{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07d99268-1579-4183-b249-18d3a2893264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b2c9f-c0be-4024-a1c7-1167cc732806",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b89c2a-9c79-4cf2-934e-250387976ba3",
   "metadata": {},
   "source": [
    "- Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdb2ae89-ea83-4b96-a4a9-63ef85102c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd7be7-e371-4596-a5fd-b164a41b1524",
   "metadata": {},
   "source": [
    "- Show head of data (first 5 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68d024bd-bcd8-4d0c-9189-265601916b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d305e9-c8e0-4f7b-b2b4-0d823c48c45d",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d2f28277-2c76-4f41-952c-a8b98c0dd502",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    continuous_features = ['LotArea', 'YearBuilt']\n",
    "    categorical_features = ['Neighborhood', 'BldgType']\n",
    "    target = 'SalePrice'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb4c2d1-88e4-4937-8506-eb40d7728a7a",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7460da-d0fc-4d28-ac1c-594c4b4286c1",
   "metadata": {},
   "source": [
    "- Create X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6afc8fed-5d81-43e4-9939-42b7be26e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into features and target\n",
    "def build_model(data: pd.DataFrame, continuous_features: list, categorical_features: list, target: str) -> dict:\n",
    "    X = data[continuous_features + categorical_features]\n",
    "    y = data[target]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a554ae7-8ab9-4d15-b086-ff37a5cde360",
   "metadata": {},
   "source": [
    "### Feature Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9c4f12fc-32ad-4ec3-ae5d-ae5f41d9556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Define pre-processing for categorical features\n",
    "    onehot = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    onehot.fit(X_train[categorical_features])\n",
    "    \n",
    "    # Define pre-processing for continuous features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[continuous_features])\n",
    "\n",
    "    # Transform the training data\n",
    "    X_train_categorical = onehot.transform(X_train[categorical_features])\n",
    "    X_train_continuous = scaler.transform(X_train[continuous_features])\n",
    "\n",
    "    # Combine processed features\n",
    "    X_train_processed = np.hstack([X_train_categorical, X_train_continuous])\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e428d50",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "66827bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prices for the test data:\n",
      "[135616. 318528. 142976. 136768. 232448. 104064. 220992. 132800.  83072.\n",
      " 141632. 146752. 150080. 128064. 327872. 193216. 141120. 197312. 145344.\n",
      " 100608. 210816. 136000. 250112. 210176. 140032. 204800. 130624. 201088.\n",
      " 159680. 193856. 181504. 101760. 327616. 181696. 143424. 254080. 153088.\n",
      " 135872. 207616. 320576. 176192. 125632. 193344. 159680. 335168. 135744.\n",
      "  98240. 150336. 137728. 336192. 149120. 135872. 158784. 109440. 205504.\n",
      " 143296. 214144. 192960. 195840. 150848. 140736. 118912. 145088. 327104.\n",
      " 257472. 234560. 131712. 157248. 227648. 173632. 173312. 153920. 140352.\n",
      " 144448. 115392. 336448. 210816. 317824. 315328. 145728. 176064.  99840.\n",
      " 101568. 151936. 149568. 149568. 126464. 250432. 204224. 143296. 214336.\n",
      " 162368. 181696. 161728. 187520. 121408. 200896. 118208. 174016. 211584.\n",
      " 195392. 161984. 207552. 166848. 120640. 266304. 144192. 155392. 317632.\n",
      " 200192. 160192. 127488. 183488. 132672. 111808. 211904. 153408. 165504.\n",
      " 157760. 128704. 327616. 118336. 143296. 191168. 123776. 211968. 144320.\n",
      " 194112. 125440. 201536. 187712. 208832. 228544. 205632. 123776. 129920.\n",
      " 332928. 269632. 181632. 206592. 330688. 323264. 149760. 184960. 146496.\n",
      " 167232. 153344. 212608. 216256. 176064.  90816. 199040. 152000. 260800.\n",
      " 129088. 104640. 139392. 125120. 145088.  97728. 135808. 215296. 169920.\n",
      " 228032. 133248. 134592. 125376. 237312. 213376. 349696. 183744. 329920.\n",
      " 166784. 144320. 103232. 314496. 193344. 121728. 216960. 116864. 153280.\n",
      " 153280. 132544. 184640. 154240. 210816. 138880. 187776. 184832. 264256.\n",
      "  83136. 118720. 132480. 213952. 158848. 242624. 123456. 179328. 100928.\n",
      " 153088. 192896. 279232. 207296. 103808. 318464. 207936. 155840. 195648.\n",
      " 136192. 161088. 154432. 195392. 149056. 147520. 173312. 217152. 250112.\n",
      " 184640. 145984. 179008. 136896. 152832. 264384. 254656. 152384. 227264.\n",
      " 150464.  99648. 145344. 176576.  81728. 125824. 185792. 144896. 143488.\n",
      " 192960. 110336. 209728. 191680. 194624. 118080. 143424. 157888. 193088.\n",
      " 347584. 184384.  68480. 150208. 214080. 111424. 159616. 216256. 187968.\n",
      " 135296. 131456. 144704. 153664. 135424.  99840. 189184. 202176. 335296.\n",
      " 258880. 184448. 193600. 249728. 256512. 111936. 142272. 144960. 192832.\n",
      " 334784. 263488. 248064. 109376. 128832. 157504.  91264. 267328. 212480.\n",
      " 135872. 214272.  82560. 247040. 140096. 214784. 178560. 211200. 148800.\n",
      " 349824. 209600. 117312. 156672.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_processed, y_train)\n",
    "\n",
    "# Save the encoder objects\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(onehot, 'Encoder.joblib')\n",
    "\n",
    "# Load the encoder objects\n",
    "loaded_onehot = joblib.load('Encoder.joblib')\n",
    "loaded_scaler = joblib.load('scaler.joblib')\n",
    "\n",
    "# Preprocess the test set\n",
    "X_test_categorical = loaded_onehot.transform(X_test[categorical_features])\n",
    "X_test_continuous = loaded_scaler.transform(X_test[continuous_features])\n",
    "\n",
    "# Combine processed features\n",
    "X_test_processed = np.hstack([X_test_categorical, X_test_continuous])\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Print predicted prices\n",
    "print(\"Predicted prices for the test data:\")\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b653458d-4545-4bf2-a39d-ee9e2ebafc19",
   "metadata": {},
   "source": [
    "\n",
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8b96d25d-2e2e-425d-8812-c063adeacd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-Mean-Squared-Error (RMSE) = 0.27\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "def compute_rmsle(y_true: np.ndarray, y_pred: np.ndarray, precision: int = 2)-> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return round(rmsle, precision)\n",
    "\n",
    "rmsle = compute_rmsle(y_test, y_pred)\n",
    "print(\"Root-Mean-Squared-Error (RMSE) =\", rmsle)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984381e0-de24-42b2-880b-6326d9ea45d3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d119b6f7-b77c-4fc2-9d19-d3f2aee582f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance: {'rmsle': 0.27}\n",
      "      PredictedSalePrice\n",
      "0               152384.0\n",
      "1               152896.0\n",
      "2               197824.0\n",
      "3               193792.0\n",
      "4               262080.0\n",
      "...                  ...\n",
      "1454             83072.0\n",
      "1455            102656.0\n",
      "1456            155456.0\n",
      "1457            174272.0\n",
      "1458            174208.0\n",
      "\n",
      "[1459 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "import os\n",
    "\n",
    "# Define constants\n",
    "CONTINUOUS_FEATURES = ['LotArea', 'YearBuilt']\n",
    "CATEGORICAL_FEATURES = ['Neighborhood', 'BldgType']\n",
    "TARGET = 'SalePrice'\n",
    "MODEL_PATH = 'C:/Users/Ananya/dsp-ananya-gownivari-ravindrareddy/models/'\n",
    "\n",
    "# Function to compute Root Mean Squared Logarithmic Error (RMSLE)\n",
    "def compute_rmsle(y_true: np.ndarray, y_pred: np.ndarray, precision: int = 2) -> float:\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return round(rmsle, precision)\n",
    "\n",
    "def build_model(data: pd.DataFrame, continuous_features: list, categorical_features: list, target: str) -> dict:\n",
    "    # Split dataset into features and target\n",
    "    X = data[continuous_features + categorical_features]\n",
    "    y = data[target]\n",
    "\n",
    "    # Split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define pre-processing for categorical features\n",
    "    onehot = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    onehot.fit(X_train[categorical_features])\n",
    "\n",
    "    # Define pre-processing for continuous features\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train[continuous_features])\n",
    "\n",
    "    # Transform the training data\n",
    "    X_train_categorical = onehot.transform(X_train[categorical_features])\n",
    "    X_train_continuous = scaler.transform(X_train[continuous_features])\n",
    "\n",
    "    # Combine processed features\n",
    "    X_train_processed = np.hstack([X_train_categorical, X_train_continuous])\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_processed, y_train)\n",
    "\n",
    "    # Save the model and preprocessors\n",
    "    joblib.dump(scaler, os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "    joblib.dump(onehot, os.path.join(MODEL_PATH, 'Encoder.joblib'))\n",
    "    joblib.dump(model, os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "\n",
    "    # Transform the test data\n",
    "    X_test_categorical = onehot.transform(X_test[categorical_features])\n",
    "    X_test_continuous = scaler.transform(X_test[continuous_features])\n",
    "    X_test_processed = np.hstack([X_test_categorical, X_test_continuous])\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "\n",
    "    # Compute performance metrics\n",
    "    rmsle = compute_rmsle(y_test, y_pred)\n",
    "    return {'rmsle': rmsle}\n",
    "\n",
    "def make_predictions(input_data: pd.DataFrame, continuous_features: list, categorical_features: list) -> np.ndarray:\n",
    "    # Load the model and preprocessors\n",
    "    loaded_model = joblib.load(os.path.join(MODEL_PATH, 'model.joblib'))\n",
    "    loaded_onehot = joblib.load(os.path.join(MODEL_PATH, 'Encoder.joblib'))\n",
    "    loaded_scaler = joblib.load(os.path.join(MODEL_PATH, 'scaler.joblib'))\n",
    "\n",
    "    # Preprocess the input data\n",
    "    X_new_categorical = loaded_onehot.transform(input_data[categorical_features])\n",
    "    X_new_continuous = loaded_scaler.transform(input_data[continuous_features])\n",
    "    X_new_processed = np.hstack([X_new_categorical, X_new_continuous])\n",
    "\n",
    "    # Make predictions\n",
    "    new_predictions = loaded_model.predict(X_new_processed)\n",
    "    return new_predictions\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the training data\n",
    "    train_data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/train.csv')\n",
    "\n",
    "    # Build the model and get performance metrics\n",
    "    performance = build_model(train_data, CONTINUOUS_FEATURES, CATEGORICAL_FEATURES, TARGET)\n",
    "    print(f'Model Performance: {performance}')\n",
    "\n",
    "    # Load the new data\n",
    "    new_data = pd.read_csv('C:/Users/Ananya/Downloads/sem 2/DSP/test.csv')\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = make_predictions(new_data, CONTINUOUS_FEATURES, CATEGORICAL_FEATURES)\n",
    "    new_data['PredictedSalePrice'] = predictions\n",
    "    print(new_data[['PredictedSalePrice']])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341becdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
